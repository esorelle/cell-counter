{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from skimage.filters.rank import entropy as sk_entropy\n",
    "from skimage.morphology import disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # VARIABLES TO CHANGE FOR YOUR LOCAL ENVIRONMENT\n",
    "base_dir = \"/home/swhite/vbox_share/cell_proliferation_elliott/ground_truth\"\n",
    "apt_gt_img_dir = os.path.join(base_dir, \"extracted_regions\")\n",
    "apt_gt_mask_dir = os.path.join(base_dir, \"extracted_regions/gt_masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_kern_size = (3, 3)\n",
    "\n",
    "# read in the apartment reference mask\n",
    "# NOTE: we are eroding the ref mask by a number of iterations here to make the external mask more aggressive\n",
    "ref_erode_iter = 5\n",
    "apt_ref_path = 'apt_ref_v3.tif'\n",
    "apt_ref_mask = cv2.imread(apt_ref_path, cv2.IMREAD_GRAYSCALE)\n",
    "apt_ref_mask = cv2.erode(apt_ref_mask, np.ones(min_kern_size), iterations=ref_erode_iter).astype(np.bool)\n",
    "\n",
    "apt_shape = apt_ref_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the backgound mask from the apt image shape\n",
    "# The background mask is an 11 pixel radius disk, \n",
    "# placed here to avoid any cells in the ground truth\n",
    "# data set.\n",
    "#\n",
    "# WARNING: DO NOT USE THIS BACKGROUND SAMPLE LOCATION IN PRODUCTION\n",
    "#     In the real library, it should be outside the apartment \n",
    "#     because there is no guarantee any region within the \n",
    "#     apartment is free from cells or debris.\n",
    "bkg_mask = np.zeros(apt_shape)\n",
    "bkg_mask = cv2.circle(bkg_mask, (130, 290), 11, 1, -1)\n",
    "bkg_mask = bkg_mask.astype(np.bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ground truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_imgs = sorted(glob.glob(os.path.join(apt_gt_img_dir, '*.tif')))\n",
    "gt_masks = sorted(glob.glob(os.path.join(apt_gt_mask_dir, '*gt_mask.tif')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(gt_imgs), len(gt_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize ground truth data as a dictionary where the main key\n",
    "# is the apartment ID, value is a dictionary with the 'img' and 'mask'\n",
    "# keys having the corresponding file paths as values\n",
    "gt_data = {}\n",
    "\n",
    "for i, img_path in enumerate(gt_imgs):\n",
    "    apt_id = os.path.basename(img_path)[-11:-4]\n",
    "    \n",
    "    gt_data[apt_id] = {\n",
    "        'img': img_path,\n",
    "        'mask': gt_masks[i]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(*imgs, title=None):\n",
    "    fig_h = 8\n",
    "    \n",
    "    img_count = len(imgs)\n",
    "    fig_w = 4 * img_count\n",
    "    \n",
    "    cmap = 'gray'\n",
    "    \n",
    "    fig = plt.figure(figsize=(fig_w, fig_h))\n",
    "    if title is not None:\n",
    "        fig.suptitle(title, fontsize=16, y=0.92)\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        if img.dtype == np.bool:\n",
    "            vmin = 0\n",
    "            vmax = 1\n",
    "            img = img.copy().astype(np.int)\n",
    "        else:\n",
    "            vmin = 0\n",
    "            vmax = 255\n",
    "        \n",
    "        ax = plt.subplot(1, img_count, i + 1)\n",
    "        plt.imshow(img, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "        \n",
    "        plt.axis('off')\n",
    "\n",
    "def normalize_to_8bit(img):\n",
    "    # normalize and convert to 8-bit\n",
    "    img = img.copy()\n",
    "    img = img - img.min()\n",
    "    img = (img / img.max()) * 255\n",
    "    img = np.floor(img).astype(np.uint8)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def create_mask_from_background(img, bkg_mask, std=3.0):\n",
    "    # Sample the background, taking its mean/std value to use as a threshold\n",
    "    img = img.copy()\n",
    "    bkg_mean = np.mean(img[bkg_mask])\n",
    "    print(bkg_mean)\n",
    "    bkg_sdt = np.std(img[bkg_mask])\n",
    "\n",
    "    img_tmp = np.zeros(img.shape)\n",
    "    img_tmp[img > (bkg_mean + (std * bkg_sdt))] = 255\n",
    "    img_mask = img_tmp.astype(np.uint8)\n",
    "    \n",
    "    return img_mask\n",
    "\n",
    "def filter_contours_by_size(mask, min_size, max_size=None):\n",
    "    ret, thresh = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(\n",
    "        thresh,\n",
    "        cv2.RETR_CCOMP,\n",
    "        cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "\n",
    "    if max_size is None:\n",
    "        max_size = mask.shape[0] * mask.shape[1]\n",
    "\n",
    "    filtered_mask = thresh.copy()\n",
    "\n",
    "    for i, c in enumerate(contours):\n",
    "        # test the bounding area first, since it's quicker than rendering each contour\n",
    "        rect = cv2.boundingRect(c)\n",
    "        rect_area = rect[2] * rect[3]\n",
    "\n",
    "        if rect_area > max_size or rect_area <= min_size:\n",
    "            # Using a new blank mask to calculate actual size of each contour\n",
    "            # because cv2.contourArea calculates the area using the Green\n",
    "            # formula, which can give a different result than the number of\n",
    "            # non-zero pixels.\n",
    "            tmp_mask = np.zeros(mask.shape)\n",
    "            cv2.drawContours(tmp_mask, contours, i, 1, cv2.FILLED, hierarchy=hierarchy)\n",
    "\n",
    "            true_area = (tmp_mask > 0).sum()\n",
    "\n",
    "            if true_area > max_size or true_area <= min_size:\n",
    "                # Black-out contour pixels\n",
    "                # TODO: Should probably collect the \"bad\" contours and erase them all at once\n",
    "                cv2.drawContours(filtered_mask, contours, i, 0, cv2.FILLED)\n",
    "\n",
    "    return filtered_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(bkg_mask, apt_ref_mask, title='reference masks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre & post processing\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "Preprocessing the apartment sub-regions may be helpful for different segmentation routines. \n",
    "\n",
    "First, the acquired images seem to have a very subtle undulating intensity variation seens as a 2-D grid in some thresholded masks. This may be the result of camera sensor irregularities or in the production of the chips themselves (slight bumps and valleys in the fabrication process).\n",
    "\n",
    "The intensity variation is addressed by applying a slight blur to the apartment sub-region. Using a kernel size of 3 x 3 pixels achieves minimal alteration of image features while nearly eliminating the intensity variation. The preprocessing function below implements this option as a Boolean rather than a configurable kernel size to avoid complex interactions with the intermediate steps employed by different segmentation techniques.\n",
    "\n",
    "The 2nd preprocessing option controls whether the parts of the image that are external to the apartment region are masked with the median value of the image. This removes the high-contrast apartment border that can cause ringing artifacts using various image processing methods such as blurring and convolution functions. \n",
    "\n",
    "NOTE: This implementation should likely change in production to choose the mask value from the median of a more reliable sub-region.\n",
    "\n",
    "### Postprocessing\n",
    "\n",
    "Postprocessing involves modifications to the mask resulting from a segmentation technique. This is currently limited to filtering contours by size to remove very small contours that some techniques are prone to generate and that might occur due to artifacts or debris in the image. And additional post-processing step could involve filling contour holes, but this is not yet implemented here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_apt_img(input_img, apt_ref_mask, blur=True, median_mask=True):\n",
    "    preproc_img = input_img.copy()\n",
    "    \n",
    "    if blur:\n",
    "        preproc_img = cv2.blur(preproc_img, ksize=min_kern_size)\n",
    "    if median_mask:\n",
    "        apt_median = np.median(preproc_img)\n",
    "        preproc_img[apt_ref_mask == False] = np.round(apt_median)\n",
    "    \n",
    "    return preproc_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup segmentation method functions\n",
    "\n",
    "## Method #1: Difference of Gaussians (really a diff of blurs)\n",
    "\n",
    "We perform a pseudo DoG...it's not really a difference of Gaussian's, \n",
    "but a difference of blurs.\n",
    "\n",
    "The bilateral blur retains edge features while blurring the background, \n",
    "where the median blur is less selective. By subtracting the heavier median \n",
    "blur, the idea is to remove the noise while retaining the edge features. \n",
    "\n",
    "The blur images are cast to signed 16 bit to allow for negative \n",
    "values from the result of the subtraction.\n",
    "\n",
    "**Inputs:**\n",
    "\n",
    " * median blur kernel size: should be >= bilateral kernel size\n",
    " * bilateral blur kernel size: ideally, should be <= size of feature of interest\n",
    "\n",
    "## Method #2: Standard deviation convolution (matlab implementation)\n",
    "\n",
    "https://www.mathworks.com/help/images/ref/stdfilt.html\n",
    "\n",
    "## Method #3: Entropy convolution (skimage implementation)\n",
    "\n",
    "https://scikit-image.org/docs/dev/auto_examples/filters/plot_entropy.html\n",
    "\n",
    "## Method #4: Inverse Canny Edge (ICE)\n",
    "\n",
    "This is similar to an inverse canny edge detection routine, though less sophisticated.\n",
    "\n",
    "Basically, this is doing a minimal blur (3x3 kernel) to remove that grid artifact, then doing a mild bilateral filter to enhance the contrast of features. The next step is to perform a double threshold to get regions above and below the background sample. The last image shows combining the lower and upper thresholded regions.\n",
    "\n",
    "What I like about this method is that it doesn't encroach the background sample region as much as the other methods, and is fairly simple and quick to calculate. The \"magic\" numbers for the kernels used are chosen as the lowest possible values to retain image detail.\n",
    "\n",
    "## Method #5: 2-pass (Row/Column) rolling standard deviation\n",
    "\n",
    "The method applies a rolling window function of the standard deviation along\n",
    "each row of the image, and then again along each column. The resulting 2 images\n",
    "are then thresholded using the background sample. The resulting masks are then\n",
    "combined using a Boolean AND operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudo DoG method\n",
    "def diff_of_blurs(\n",
    "        input_img, \n",
    "        bkg_mask, \n",
    "        median_kernel_size=31, \n",
    "        bilat_kernel_size=7,\n",
    "        bkg_stdev_thresh=3.0\n",
    "):\n",
    "    blur_median = cv2.medianBlur(input_img, ksize=median_kernel_size)\n",
    "    blur_bilateral = cv2.bilateralFilter(input_img, d=bilat_kernel_size, sigmaColor=5, sigmaSpace=31)\n",
    "\n",
    "    dog_img = blur_bilateral.astype(np.int16) - blur_median.astype(np.int16)\n",
    "\n",
    "    # normalize and convert to 8-bit\n",
    "    dog_img = normalize_to_8bit(dog_img)\n",
    "\n",
    "    # mask result based on background sample\n",
    "    dog_img_mask = create_mask_from_background(dog_img, bkg_mask, std=bkg_stdev_thresh)\n",
    "    \n",
    "    return dog_img, dog_img_mask\n",
    "\n",
    "def std_dev_conv(\n",
    "        input_img,\n",
    "        bkg_mask,\n",
    "        conv_kernel_size=11,\n",
    "        bkg_stdev_thresh=3.0\n",
    "):\n",
    "    std_dev_kernel = np.ones((conv_kernel_size, conv_kernel_size))\n",
    "    n = std_dev_kernel.sum()\n",
    "    n1 = n - 1\n",
    "    \n",
    "    c1 = cv2.filter2D(\n",
    "        input_img.astype(np.float32) ** 2, \n",
    "        -1, \n",
    "        std_dev_kernel / n1, \n",
    "        borderType=cv2.BORDER_REFLECT\n",
    "    )\n",
    "    c2 = cv2.filter2D(\n",
    "        input_img.astype(np.float32), \n",
    "        -1, \n",
    "        std_dev_kernel, \n",
    "        borderType=cv2.BORDER_REFLECT\n",
    "    )\n",
    "    c2 = c2 ** 2 / (n * n1)\n",
    "    \n",
    "    std_dev_matlab_img = np.sqrt(np.maximum(c1 - c2, 0))\n",
    "\n",
    "    # normalize and convert to 8-bit\n",
    "    std_dev_matlab_img = normalize_to_8bit(std_dev_matlab_img)\n",
    "\n",
    "    # mask result based on background sample\n",
    "    std_dev_matlab_img_mask = create_mask_from_background(std_dev_matlab_img, bkg_mask, std=bkg_stdev_thresh)\n",
    "    \n",
    "    return std_dev_matlab_img, std_dev_matlab_img_mask\n",
    "\n",
    "def entropy(\n",
    "        input_img,\n",
    "        bkg_mask,\n",
    "        entropy_kernel_size=11,\n",
    "        bkg_stdev_thresh=3.0\n",
    "):\n",
    "    ent_img = sk_entropy(input_img, disk(entropy_kernel_size))\n",
    "\n",
    "    # normalize and convert to 8-bit\n",
    "    ent_img = normalize_to_8bit(ent_img)\n",
    "    \n",
    "    # mask result based on background sample\n",
    "    ent_mask = create_mask_from_background(ent_img, bkg_mask, std=bkg_stdev_thresh)\n",
    "    \n",
    "    return ent_img, ent_mask\n",
    "\n",
    "def ice(\n",
    "        input_img,\n",
    "        bkg_mask,\n",
    "        blur_kernel_size=5,\n",
    "        bkg_stdev_thresh=3.0\n",
    "):\n",
    "    ice_img = cv2.bilateralFilter(~input_img, d=blur_kernel_size, sigmaColor=15, sigmaSpace=7)\n",
    "\n",
    "    # normalize and convert to 8-bit\n",
    "    ice_img = normalize_to_8bit(ice_img)\n",
    "\n",
    "    # mask results based on background sample\n",
    "    ice_mask1 = create_mask_from_background(ice_img, bkg_mask, std=bkg_stdev_thresh)\n",
    "    ice_mask2 = create_mask_from_background(~ice_img, bkg_mask, std=bkg_stdev_thresh)\n",
    "    \n",
    "    ice_mask_final = np.logical_or(ice_mask1, ice_mask2).astype(np.uint8) * 255\n",
    "    \n",
    "    return ice_img, ice_mask_final\n",
    "\n",
    "def rolling_2d_std_dev(\n",
    "        input_img,\n",
    "        roll_size=21,\n",
    "        std_dev=3.0\n",
    "):\n",
    "    row_scan_img = np.zeros(input_img.shape, dtype=np.float64)\n",
    "    col_scan_img = np.zeros(input_img.shape, dtype=np.float64)\n",
    "    row_scan_mask = np.zeros(input_img.shape, dtype=np.bool)\n",
    "    col_scan_mask = np.zeros(input_img.shape, dtype=np.bool)\n",
    "\n",
    "    for i, row in enumerate(input_img):\n",
    "        row_roll_std = pd.Series(row).rolling(roll_size, center=True).std()\n",
    "        row_roll_std[row_roll_std.isna()] = 0\n",
    "        row_scan_img[i, :] = row_roll_std\n",
    "        row_scan_mask[i, :] = row_roll_std > std_dev\n",
    "\n",
    "    for i, col in enumerate(input_img.T):\n",
    "        col_roll_std = pd.Series(col).rolling(roll_size, center=True).std()\n",
    "        col_roll_std[col_roll_std.isna()] = 0\n",
    "        col_scan_img[:, i] = col_roll_std\n",
    "        col_scan_mask[:, i] = col_roll_std > std_dev\n",
    "\n",
    "    # create average from row/col images\n",
    "    scan_img_combined = np.mean(np.array([row_scan_img, col_scan_img]), axis=0)\n",
    "    # scan_img_combined = row_scan_img * col_scan_img\n",
    "    scan_img_combined = normalize_to_8bit(scan_img_combined)\n",
    "    \n",
    "    # combine union of row/col masks\n",
    "    scan_mask_combined = np.logical_and(row_scan_mask, col_scan_mask)\n",
    "    scan_mask_combined = scan_mask_combined.astype(np.uint8) * 255\n",
    "\n",
    "    # process result w/ morph close\n",
    "    scan_mask_combo_close = cv2.morphologyEx(\n",
    "        scan_mask_combined, \n",
    "        cv2.MORPH_CLOSE, \n",
    "        kernel=np.ones(min_kern_size)\n",
    "    )\n",
    "    \n",
    "    return scan_img_combined, scan_mask_combo_close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick an apartment\n",
    "# REMINDER: \n",
    "#     All data is loaded in the gt_data dictionary \n",
    "#     - keys are apt IDs,\n",
    "#     - value is a dict with keys 'img' and 'mask' \n",
    "#     - 'img' & 'mask' hold the extracted apartment region and ground truth mask, respectively \n",
    "apt_id = '008_001'\n",
    "apt_img = cv2.imread(gt_data[apt_id]['img'], cv2.IMREAD_GRAYSCALE)\n",
    "gt_apt_mask = cv2.imread(gt_data[apt_id]['mask'], cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(apt_img, title=apt_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def light_correction(input_img, ksize=15, sigma=3.0):\n",
    "    img_blur = cv2.GaussianBlur(input_img, (ksize, ksize), sigma)\n",
    "    img_corr = input_img / img_blur\n",
    "\n",
    "    # Translate to zero, then normalize to 8-bit range\n",
    "    img_corr = img_corr - img_corr.min()\n",
    "    img_corr = np.floor((img_corr / img_corr.max()) * 255.0)\n",
    "    img_corr = img_corr.astype(np.uint8)\n",
    "\n",
    "    return img_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_corr_base = light_correction(apt_img)\n",
    "img_corr1 = light_correction(apt_img, sigma=3.0)\n",
    "img_corr2 = light_correction(apt_img, ksize=15, sigma=5)\n",
    "img_corr3 = light_correction(apt_img, ksize=21, sigma=5)\n",
    "img_corr4 = light_correction(apt_img, ksize=7, sigma=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(apt_img, img_corr4, img_corr2, img_corr3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DoG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "median_kernel_size=31\n",
    "bilat_kernel_size=7\n",
    "\n",
    "dog_input = light_correction(apt_img, ksize=15, sigma=5.0)\n",
    "\n",
    "# run the DoG method without any pre or post-processing\n",
    "dog_img, dog_mask = diff_of_blurs(\n",
    "    dog_input, bkg_mask, median_kernel_size=median_kernel_size, bilat_kernel_size=bilat_kernel_size\n",
    ")\n",
    "\n",
    "imshow(dog_img, dog_mask, title=\"%s - DoG - NoPre\" % apt_id)\n",
    "\n",
    "# run the DoG method with pre-processing of just blur\n",
    "apt_img_preproc = preprocess_apt_img(dog_input, apt_ref_mask, blur=True, median_mask=False)\n",
    "dog_img, dog_mask = diff_of_blurs(\n",
    "    apt_img_preproc, bkg_mask, median_kernel_size=median_kernel_size, bilat_kernel_size=bilat_kernel_size\n",
    ")\n",
    "imshow(dog_img, dog_mask, title=\"%s - DoG - PreBlurOnly\" % apt_id)\n",
    "\n",
    "# run the DoG method with pre-processing of min blur and external apt median masking\n",
    "apt_img_preproc = preprocess_apt_img(dog_input, apt_ref_mask, blur=True, median_mask=True)\n",
    "dog_img, dog_mask = diff_of_blurs(\n",
    "    apt_img_preproc, bkg_mask, median_kernel_size=median_kernel_size, bilat_kernel_size=bilat_kernel_size\n",
    ")\n",
    "imshow(dog_img, dog_mask, title=\"%s - DoG - Pre blur+mask\" % apt_id)\n",
    "\n",
    "# Run Dog with all pre-processing and post-processing\n",
    "# run the DoG method with pre-processing of min blur and external apt median masking\n",
    "apt_img_preproc = preprocess_apt_img(apt_img, apt_ref_mask, blur=True, median_mask=True)\n",
    "dog_img, dog_mask = diff_of_blurs(\n",
    "    apt_img_preproc, bkg_mask, median_kernel_size=median_kernel_size, bilat_kernel_size=bilat_kernel_size\n",
    ")\n",
    "dog_mask = filter_contours_by_size(dog_mask, min_size=9 * 9)\n",
    "\n",
    "imshow(dog_img, dog_mask, title=\"%s - DoG - FullPre + Post\" % apt_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StdDev Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conv_kern_size = 5\n",
    "std_dev = 12.0\n",
    "\n",
    "# run the DoG method without any pre or post-processing\n",
    "output_img, output_mask = std_dev_conv(apt_img, bkg_mask, conv_kernel_size=conv_kern_size)\n",
    "\n",
    "imshow(output_img, output_mask, title=\"%s - Std - NoPre\" % apt_id)\n",
    "\n",
    "# run the DoG method with pre-processing of just blur\n",
    "apt_img_preproc = preprocess_apt_img(apt_img, apt_ref_mask, blur=True, median_mask=False)\n",
    "output_img, output_mask = std_dev_conv(\n",
    "    apt_img_preproc, bkg_mask, conv_kernel_size=conv_kern_size, bkg_stdev_thresh=std_dev\n",
    ")\n",
    "\n",
    "imshow(output_img, output_mask, title=\"%s - Std - PreBlurOnly\" % apt_id)\n",
    "\n",
    "# run the DoG method with pre-processing of min blur and external apt median masking\n",
    "apt_img_preproc = preprocess_apt_img(apt_img, apt_ref_mask, blur=True, median_mask=True)\n",
    "output_img, output_mask = std_dev_conv(\n",
    "    apt_img_preproc, bkg_mask, conv_kernel_size=conv_kern_size, bkg_stdev_thresh=std_dev\n",
    ")\n",
    "imshow(output_img, output_mask, title=\"%s - Std - Pre blur+mask\" % apt_id)\n",
    "\n",
    "# Run Dog with all pre-processing and post-processing\n",
    "# run the DoG method with pre-processing of min blur and external apt median masking\n",
    "apt_img_preproc = preprocess_apt_img(apt_img, apt_ref_mask, blur=True, median_mask=True)\n",
    "output_img, output_mask = std_dev_conv(\n",
    "    apt_img_preproc, bkg_mask, conv_kernel_size=conv_kern_size, bkg_stdev_thresh=std_dev\n",
    ")\n",
    "output_mask = filter_contours_by_size(output_mask, min_size=9 * 9)\n",
    "\n",
    "imshow(output_img, output_mask, title=\"%s - Std - FullPre + Post\" % apt_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ent_kern_size = 5\n",
    "std_dev = 6.0\n",
    "\n",
    "# run method without any pre or post-processing\n",
    "output_img, output_mask = entropy(\n",
    "    apt_img, bkg_mask, entropy_kernel_size=ent_kern_size, bkg_stdev_thresh=std_dev\n",
    ")\n",
    "\n",
    "imshow(output_img, output_mask, title=\"%s - Ent - NoPre\" % apt_id)\n",
    "\n",
    "# run with pre-processing of just blur\n",
    "apt_img_preproc = preprocess_apt_img(apt_img, apt_ref_mask, blur=True, median_mask=False)\n",
    "output_img, output_mask = entropy(\n",
    "    apt_img_preproc, bkg_mask, entropy_kernel_size=ent_kern_size, bkg_stdev_thresh=std_dev\n",
    ")\n",
    "\n",
    "imshow(output_img, output_mask, title=\"%s - Ent - PreBlurOnly\" % apt_id)\n",
    "\n",
    "# run with pre-processing of min blur and external apt median masking\n",
    "apt_img_preproc = preprocess_apt_img(apt_img, apt_ref_mask, blur=True, median_mask=True)\n",
    "output_img, output_mask = entropy(\n",
    "    apt_img_preproc, bkg_mask, entropy_kernel_size=ent_kern_size, bkg_stdev_thresh=std_dev\n",
    ")\n",
    "imshow(output_img, output_mask, title=\"%s - Ent - Pre blur+mask\" % apt_id)\n",
    "\n",
    "# run with all pre-processing and post-processing\n",
    "apt_img_preproc = preprocess_apt_img(apt_img, apt_ref_mask, blur=True, median_mask=True)\n",
    "output_img, output_mask = entropy(\n",
    "    apt_img_preproc, bkg_mask, entropy_kernel_size=ent_kern_size, bkg_stdev_thresh=std_dev\n",
    ")\n",
    "output_mask = filter_contours_by_size(output_mask, min_size=9 * 9)\n",
    "\n",
    "imshow(output_img, output_mask, title=\"%s - Ent - FullPre + Post\" % apt_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ice_kern_size = 13\n",
    "std_dev = 6.0\n",
    "\n",
    "meth_input = apt_img.copy()\n",
    "meth_input = light_correction(dog_input, ksize=31, sigma=3.0)\n",
    "\n",
    "# run method without any pre or post-processing\n",
    "output_img, output_mask = ice(meth_input, bkg_mask, blur_kernel_size=ice_kern_size, bkg_stdev_thresh=std_dev)\n",
    "\n",
    "imshow(output_img, output_mask, title=\"%s - DoG - NoPre\" % apt_id)\n",
    "\n",
    "# run with pre-processing of just blur\n",
    "apt_img_preproc = preprocess_apt_img(meth_input, apt_ref_mask, blur=True, median_mask=False)\n",
    "output_img, output_mask = ice(apt_img_preproc, bkg_mask, blur_kernel_size=ice_kern_size, bkg_stdev_thresh=std_dev)\n",
    "\n",
    "imshow(output_img, output_mask, title=\"%s - DoG - PreBlurOnly\" % apt_id)\n",
    "\n",
    "# run with pre-processing of min blur and external apt median masking\n",
    "apt_img_preproc = preprocess_apt_img(meth_input, apt_ref_mask, blur=True, median_mask=True)\n",
    "output_img, output_mask = ice(apt_img_preproc, bkg_mask, blur_kernel_size=ice_kern_size, bkg_stdev_thresh=std_dev)\n",
    "\n",
    "imshow(output_img, output_mask, title=\"%s - DoG - Pre blur+mask\" % apt_id)\n",
    "\n",
    "# run with all pre-processing and post-processing\n",
    "apt_img_preproc = preprocess_apt_img(meth_input, apt_ref_mask, blur=True, median_mask=True)\n",
    "output_img, output_mask = ice(apt_img_preproc, bkg_mask, blur_kernel_size=ice_kern_size, bkg_stdev_thresh=std_dev)\n",
    "\n",
    "output_mask = filter_contours_by_size(output_mask, min_size=9 * 9)\n",
    "\n",
    "imshow(output_img, output_mask, title=\"%s - DoG - FullPre + Post\" % apt_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling 2-D Std Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "roll_size = 21\n",
    "std_dev = 2.0\n",
    "\n",
    "meth_input = apt_img.copy()\n",
    "meth_input = light_correction(dog_input, ksize=31, sigma=3.0)\n",
    "\n",
    "# run method without any pre or post-processing\n",
    "output_img, output_mask = rolling_2d_std_dev(meth_input, roll_size=roll_size, std_dev=std_dev)\n",
    "\n",
    "imshow(output_img, output_mask, title=\"%s - DoG - NoPre\" % apt_id)\n",
    "\n",
    "# run with pre-processing of just blur\n",
    "apt_img_preproc = preprocess_apt_img(meth_input, apt_ref_mask, blur=True, median_mask=False)\n",
    "output_img, output_mask = rolling_2d_std_dev(apt_img_preproc, roll_size=roll_size, std_dev=std_dev)\n",
    "\n",
    "imshow(output_img, output_mask, title=\"%s - DoG - PreBlurOnly\" % apt_id)\n",
    "\n",
    "# run with pre-processing of min blur and external apt median masking\n",
    "apt_img_preproc = preprocess_apt_img(meth_input, apt_ref_mask, blur=True, median_mask=True)\n",
    "output_img, output_mask = rolling_2d_std_dev(apt_img_preproc, roll_size=roll_size, std_dev=std_dev)\n",
    "\n",
    "imshow(output_img, output_mask, title=\"%s - DoG - Pre blur+mask\" % apt_id)\n",
    "\n",
    "# run with all pre-processing and post-processing\n",
    "apt_img_preproc = preprocess_apt_img(meth_input, apt_ref_mask, blur=True, median_mask=True)\n",
    "output_img, output_mask = rolling_2d_std_dev(apt_img_preproc, roll_size=roll_size, std_dev=std_dev)\n",
    "\n",
    "output_mask = filter_contours_by_size(output_mask, min_size=9 * 9)\n",
    "\n",
    "imshow(output_img, output_mask, title=\"%s - DoG - FullPre + Post\" % apt_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
